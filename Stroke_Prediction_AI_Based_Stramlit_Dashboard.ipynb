{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86_7F76rjIwI",
        "outputId": "a640b1d2-d4ac-46c1-90ac-2ad4e8e24651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "App running at: NgrokTunnel: \"https://5a0a-35-185-162-173.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install streamlit pyngrok pandas scikit-learn xgboost tensorflow --quiet\n",
        "\n",
        "# Clean up processes\n",
        "!pkill ngrok 2>/dev/null || true\n",
        "!rm -rf /root/.ngrok2\n",
        "\n",
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def load_data():\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/stroke_risk_dataset_v2.csv\")  # Replace with your dataset path\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    label_encoders = {}\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "        label_encoders[col] = le\n",
        "\n",
        "    X = df.drop(columns=[\"stroke_risk_percentage\", \"at_risk\"])\n",
        "    y = df[\"at_risk\"]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    return train_test_split(X_scaled, y, test_size=0.2, random_state=42), scaler, label_encoders\n",
        "\n",
        "def train_models(X_train, X_test, y_train, y_test):\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(),\n",
        "        \"Random Forest\": RandomForestClassifier(),\n",
        "        \"XGBoost\": XGBClassifier(enable_categorical=True),\n",
        "        \"SVM\": SVC(probability=True),\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        results[name] = (model, acc)\n",
        "\n",
        "    nn_model = Sequential([\n",
        "        Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        Dense(8, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    nn_model.fit(X_train, y_train, epochs=20, batch_size=16, verbose=0)\n",
        "    acc = nn_model.evaluate(X_test, y_test, verbose=0)[1]\n",
        "    results[\"Neural Network\"] = (nn_model, acc)\n",
        "\n",
        "    best_model_name = max(results, key=lambda k: results[k][1])\n",
        "    best_model = results[best_model_name][0]\n",
        "\n",
        "    return best_model, best_model_name\n",
        "\n",
        "def save_model(model, scaler):\n",
        "    joblib.dump(model, \"best_model.pkl\")\n",
        "    joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "def load_model():\n",
        "    model = joblib.load(\"best_model.pkl\")\n",
        "    scaler = joblib.load(\"scaler.pkl\")\n",
        "    return model, scaler\n",
        "\n",
        "st.title(\"Stroke Risk Prediction App By Umar\")\n",
        "\n",
        "df = load_data()\n",
        "(X_train, X_test, y_train, y_test), scaler, label_encoders = preprocess_data(df)\n",
        "best_model, best_model_name = train_models(X_train, X_test, y_train, y_test)\n",
        "save_model(best_model, scaler)\n",
        "st.write(f\"‚úÖ Best model selected: **{best_model_name}**\")\n",
        "\n",
        "# Instructions\n",
        "st.write(\\\"\"\"\n",
        "### ‚ÑπÔ∏è How to Enter Information:\n",
        "- **Gender**: Enter `1` for **Male**, `0` for **Female**\n",
        "- **Age**: Use the **slider** below (0‚Äì150)\n",
        "- **All Other Fields**: Enter `1` for **Yes**, `0` for **No**\n",
        "\\\"\"\")\n",
        "\n",
        "# Sidebar inputs\n",
        "st.sidebar.header(\"Enter Patient Details\")\n",
        "input_data = []\n",
        "columns = df.drop(columns=[\"stroke_risk_percentage\", \"at_risk\"]).columns\n",
        "\n",
        "for col in columns:\n",
        "    if col.lower() == \"age\":\n",
        "        value = st.sidebar.slider(\"Age\", min_value=0, max_value=150, value=30)\n",
        "    else:\n",
        "        value = st.sidebar.number_input(col, min_value=0, max_value=1, value=0)\n",
        "    input_data.append(value)\n",
        "\n",
        "# Prediction\n",
        "if st.sidebar.button(\"Predict Stroke Risk\"):\n",
        "    model, scaler = load_model()\n",
        "    input_array = np.array(input_data).reshape(1, -1)\n",
        "    input_scaled = scaler.transform(input_array)\n",
        "    prediction = model.predict(input_scaled)\n",
        "    result = \"üî¥ High Risk\" if prediction[0] == 1 else \"üü¢ Low Risk\"\n",
        "    st.write(f\"### üéØ Predicted Stroke Risk: {result}\")\n",
        "\"\"\"\n",
        "\n",
        "# Save the modified app code to file\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "# Run the app\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "ngrok.set_auth_token(\"2vIWUZO3KsrfEqqficQZqwHwxxo_3dh4bmQjD7TdeA9BExntU\")\n",
        "process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"])\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"App running at:\", public_url)\n"
      ]
    }
  ]
}
